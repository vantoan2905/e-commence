{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_file = r'D:\\recomments_product\\recomment_product\\db.sqlite3'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(db_file)\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "def fetch_table_as_df(cursor, table_name):\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]  \n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fetch data\n",
    "df_product = fetch_table_as_df(cursor, \"shop_product\")\n",
    "df_user = fetch_table_as_df(cursor, \"auth_user\")\n",
    "df_rating = fetch_table_as_df(cursor, \"shop_rating\")\n",
    "df_search_history = fetch_table_as_df(cursor, \"shop_searchhistory\")\n",
    "df_view_history = fetch_table_as_df(cursor, \"shop_viewhistory\")\n",
    "\n",
    "# Close connection\n",
    "connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search product by Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product table!\n",
      "       image  price articleNumber articleType  \\\n",
      "0  10000.jpg  834.0    5410480144      Skirts   \n",
      "1  10001.jpg  834.0    5410480144      Skirts   \n",
      "2  10002.jpg  834.0    5410480144      Skirts   \n",
      "3  10003.jpg  834.0    5410480144     Tshirts   \n",
      "4  10004.jpg  834.0    5410480144      Shorts   \n",
      "\n",
      "                             productDisplayName masterCategory subCategory  \\\n",
      "0      Palm Tree Girls Sp Jace Sko White Skirts        Apparel  Bottomwear   \n",
      "1  Palm Tree Kids Girls Sp Jema Skt Blue Skirts        Apparel  Bottomwear   \n",
      "2        Palm Tree Kids Sp Jema Skt Blue Skirts        Apparel  Bottomwear   \n",
      "3        Nike Women As Nike Eleme White T-Shirt        Apparel     Topwear   \n",
      "4             Nike Men As 7 Sw Temp Grey Shorts        Apparel  Bottomwear   \n",
      "\n",
      "  gender baseColour fashionType  season    year    usag  \n",
      "0  Women      White     Fashion  Summer  2011.0  Casual  \n",
      "1  Women       Blue     Fashion  Summer  2011.0  Casual  \n",
      "2  Women       Blue     Fashion  Summer  2011.0  Casual  \n",
      "3  Women      White     Fashion    Fall  2011.0  Sports  \n",
      "4    Men       Grey     Fashion    Fall  2011.0  Sports  \n",
      "User table!\n",
      "                                            password last_login  is_superuser  \\\n",
      "0  pbkdf2_sha256$870000$kqqmmiqB5l4Z8pfIuXoeZF$BX...       None             0   \n",
      "1  pbkdf2_sha256$870000$kBxttmUN6Ll0xCKtIWi0dp$++...       None             0   \n",
      "2  pbkdf2_sha256$870000$rU9GV3UCzaQqqir0xpdBA6$Ka...       None             0   \n",
      "3  pbkdf2_sha256$870000$5JXUVfzCaLQdfg8fBiNDT5$Vv...       None             0   \n",
      "4  pbkdf2_sha256$870000$B6UxFQp52aEge5j7GEMvqh$S/...       None             0   \n",
      "\n",
      "       username last_name                      email  is_staff  is_active  \\\n",
      "0      jillkerr      Mata   jessicamorse@example.org         0          1   \n",
      "1       ymartin    Butler       nathan25@example.net         0          1   \n",
      "2  aguilardebra   Edwards      stephen80@example.com         0          1   \n",
      "3      djohnson     Nolan  waltercharles@example.net         0          1   \n",
      "4       dbutler    Morris      carolyn30@example.com         0          1   \n",
      "\n",
      "                  date_joined first_name  \n",
      "0  2024-12-19 09:22:41.677443    Roberto  \n",
      "1  2024-12-19 09:22:42.173708    Michael  \n",
      "2  2024-12-19 09:22:42.646637      Kelly  \n",
      "3  2024-12-19 09:22:43.115494      Laura  \n",
      "4  2024-12-19 09:22:43.578706   Kimberly  \n",
      "Search history table!\n",
      "          query          search_date  user_id\n",
      "0  Sports Shoes  2024-05-04 06:57:31        1\n",
      "1          Pink  2024-03-21 07:52:12        1\n",
      "2        Shorts  2024-08-01 04:23:41        1\n",
      "3       Tshirts  2024-02-22 19:23:48        1\n",
      "4       Tshirts  2024-04-29 20:28:35        2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Embedding data\n",
    "\n",
    "# Data for task process\n",
    "# df_product \n",
    "# df_user \n",
    "# df_search_history\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "#############################################################################################################\n",
    "# View data \n",
    "print(\"Product table!\")\n",
    "print(df_product.head())\n",
    "print(\"User table!\")\n",
    "print(df_user.head())\n",
    "print(\"Search history table!\")\n",
    "print(df_search_history.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check product table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acticleType\n",
      "articleType\n",
      "Tshirts                7067\n",
      "Shirts                 3217\n",
      "Casual Shoes           2845\n",
      "Watches                2542\n",
      "Sports Shoes           2036\n",
      "                       ... \n",
      "Ipad                      1\n",
      "Body Wash and Scrub       1\n",
      "Mens Grooming Kit         1\n",
      "Hair Accessory            1\n",
      "Shoe Laces                1\n",
      "Name: count, Length: 143, dtype: int64\n",
      "gender\n",
      "gender\n",
      "Men       22147\n",
      "Women     18631\n",
      "Unisex     2161\n",
      "Boys        830\n",
      "Girls       655\n",
      "Name: count, dtype: int64\n",
      "baseColour\n",
      "baseColour\n",
      "Black                9728\n",
      "White                5538\n",
      "Blue                 4918\n",
      "Brown                3494\n",
      "Grey                 2741\n",
      "Red                  2455\n",
      "Green                2115\n",
      "Pink                 1860\n",
      "Navy Blue            1789\n",
      "Purple               1640\n",
      "Silver               1090\n",
      "Yellow                778\n",
      "Beige                 749\n",
      "Gold                  628\n",
      "Maroon                581\n",
      "Orange                530\n",
      "Olive                 410\n",
      "Multi                 394\n",
      "Cream                 390\n",
      "Steel                 315\n",
      "Charcoal              228\n",
      "Peach                 195\n",
      "Off White             182\n",
      "Skin                  179\n",
      "Lavender              162\n",
      "Grey Melange          146\n",
      "Khaki                 139\n",
      "Magenta               129\n",
      "Teal                  120\n",
      "Tan                   114\n",
      "Mustard                97\n",
      "Bronze                 95\n",
      "Copper                 86\n",
      "Turquoise Blue         69\n",
      "Rust                   66\n",
      "Burgundy               45\n",
      "Metallic               43\n",
      "Coffee Brown           31\n",
      "Mauve                  29\n",
      "Rose                   28\n",
      "Nude                   23\n",
      "Sea Green              22\n",
      "Mushroom Brown         16\n",
      "nan                    15\n",
      "Taupe                  11\n",
      "Lime Green              6\n",
      "Fluorescent Green       5\n",
      "Name: count, dtype: int64\n",
      "fashionType\n",
      "fashionType\n",
      "Fashion    44424\n",
      "Name: count, dtype: int64\n",
      "season\n",
      "season\n",
      "Summer    21472\n",
      "Fall      11431\n",
      "Winter     8517\n",
      "Spring     2983\n",
      "nan          21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_product.head()\n",
    "\n",
    "articleType = df_product['articleType'].value_counts()\n",
    "gender = df_product['gender'].value_counts()\n",
    "baseColour = df_product['baseColour'].value_counts()\n",
    "fashionType = df_product['fashionType'].value_counts()\n",
    "season = df_product['season'].value_counts()\n",
    "\n",
    "\n",
    "print(\"acticleType\")\n",
    "print(articleType)\n",
    "print(\"gender\")\n",
    "print(gender)\n",
    "print(\"baseColour\")\n",
    "print(baseColour)\n",
    "print(\"fashionType\")\n",
    "print(fashionType)\n",
    "print(\"season\")\n",
    "print(season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificaion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enable GPU memory growth to prevent TF from taking all memory\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "class CustomDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, img_paths, labels, batch_size=32, img_size=(224, 224), shuffle=True):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.img_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.img_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_paths = [self.img_paths[i] for i in batch_indexes]\n",
    "        \n",
    "        X = np.zeros((len(batch_indexes), self.img_size[0], self.img_size[1], 3))\n",
    "        y = np.array([self.labels[i] for i in batch_indexes])\n",
    "        \n",
    "        for i, path in enumerate(batch_paths):\n",
    "            try:\n",
    "                img = keras.preprocessing.image.load_img(path, target_size=self.img_size)\n",
    "                img = keras.preprocessing.image.img_to_array(img)\n",
    "                img = applications.mobilenet_v2.preprocess_input(img)\n",
    "                X[i] = img\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {path}: {str(e)}\")\n",
    "                # Fill with zeros if image loading fails\n",
    "                X[i] = np.zeros(self.img_size + (3,))\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "def analyze_class_distribution(df, label_col):\n",
    "    \"\"\"Analyze class distribution and print statistics\"\"\"\n",
    "    class_counts = df[label_col].value_counts()\n",
    "    # print(\"\\nClass Distribution Analysis:\")\n",
    "    # print(f\"Total number of classes: {len(class_counts)}\")\n",
    "    # print(f\"Classes with only one example: {sum(class_counts == 1)}\")\n",
    "    # print(\"\\nClass counts:\")\n",
    "    # print(class_counts)\n",
    "    return class_counts\n",
    "\n",
    "def filter_rare_classes(df, label_col, min_examples=2):\n",
    "    \"\"\"Filter out classes with fewer than min_examples\"\"\"\n",
    "    class_counts = df[label_col].value_counts()\n",
    "    valid_classes = class_counts[class_counts >= min_examples].index\n",
    "    filtered_df = df[df[label_col].isin(valid_classes)].copy()\n",
    "    \n",
    "    # print(f\"\\nFiltering results:\")\n",
    "    # print(f\"Original number of samples: {len(df)}\")\n",
    "    # print(f\"Filtered number of samples: {len(filtered_df)}\")\n",
    "    # print(f\"Original number of classes: {len(class_counts)}\")\n",
    "    # print(f\"Filtered number of classes: {len(valid_classes)}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def create_model(num_classes):\n",
    "    base_model = applications.MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_generator, validation_generator, epochs=5):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    os.makedirs('model_output', exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'model_output/best_model.keras',  \n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy'\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir='model_output/logs',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_output/training_history.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 411/1111\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:21\u001b[0m 460ms/step - accuracy: 0.5203 - loss: 2.0905Error loading image D:\\recomments_product\\recomment_product\\media\\39425.jpg: [Errno 2] No such file or directory: 'D:\\\\recomments_product\\\\recomment_product\\\\media\\\\39425.jpg'\n",
      "\u001b[1m 481/1111\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:49\u001b[0m 459ms/step - accuracy: 0.5407 - loss: 1.9816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     label_mapping_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output/label_mapping.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m CustomDataGenerator(\n\u001b[0;32m     22\u001b[0m     val_paths, val_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(num_classes)\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m plot_training_history(history)\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output/final_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "Cell \u001b[1;32mIn[7], line 118\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_generator, validation_generator, epochs)\u001b[0m\n\u001b[0;32m     93\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     95\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     96\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output/best_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m ]\n\u001b[1;32m--> 118\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\toanv\\anaconda3\\envs\\django_recomment_system\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    img_dir = r\"D:\\recomments_product\\recomment_product\\media\"\n",
    "    \n",
    "    analyze_class_distribution(df_product, 'articleType')\n",
    "    \n",
    "    filtered_df = filter_rare_classes(df_product, 'articleType', min_examples=2)\n",
    "    \n",
    "    label_mapping = {label: idx for idx, label in enumerate(filtered_df['articleType'].unique())}\n",
    "    num_classes = len(label_mapping)\n",
    "    labels = filtered_df['articleType'].map(label_mapping).values\n",
    "    \n",
    "    img_paths = [os.path.join(img_dir, img_name) for img_name in filtered_df['image']]\n",
    "    \n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        img_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    train_generator = CustomDataGenerator(\n",
    "        train_paths, train_labels, batch_size=32, shuffle=True\n",
    "    )\n",
    "    validation_generator = CustomDataGenerator(\n",
    "        val_paths, val_labels, batch_size=32, shuffle=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = create_model(num_classes)\n",
    "    history = train_model(model, train_generator, validation_generator)\n",
    "    \n",
    "    plot_training_history(history)\n",
    "    \n",
    "    model.save('model_output/final_model.keras')  \n",
    "    \n",
    "    label_mapping_df = pd.DataFrame(list(label_mapping.items()), columns=['class', 'index'])\n",
    "    label_mapping_df.to_csv('model_output/label_mapping.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django_recomment_system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
